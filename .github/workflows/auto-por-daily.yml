name: Auto PoR Pipeline

on:
  schedule:
    - cron: '0 6 * * *'
  workflow_dispatch:

jobs:
  por-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 60   # BLEURT モデルDLの余裕確保
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Cache HF models
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-hf-${{ hashFiles('requirements.txt') }}

      - name: Install deps
        run: |
          pip install "numpy>=1.22"
          pip install -r requirements.txt
          pip install bert-score evaluate matplotlib seaborn scikit-learn

      - name: Collect 50 QA pairs
        run: |
          python facade/collector.py --auto -n 50 \
            --q-provider openai --ai-provider openai \
            --quiet --output daily_raw.csv

      - name: Score baseline metrics
        run: |
          python scripts/auto_score.py \
            --input daily_raw.csv --output daily_scored.csv

      - name: Analyze & generate report
        run: |
          REPORT_DIR="reports/$(date +%Y%m%d)"
          mkdir -p "$REPORT_DIR"
          python scripts/auto_analysis.py \
            --input daily_scored.csv --report-dir "$REPORT_DIR"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: por_dataset_${{ github.run_number }}
          path: |
            daily_scored.csv
            ${{ github.workspace }}/reports/**
          if-no-files-found: ignore
