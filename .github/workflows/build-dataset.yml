name: Build Dataset

########################################
# A. 同時実行を 1 本に制限
########################################
concurrency:
  group: build-dataset-main          # ← 任意のグループ名
  cancel-in-progress: true           # 古い run をキャンセル

on:
  workflow_dispatch:
    inputs:
      turns:
        type: number
        default: 30
  schedule:
    - cron: '0 3 * * *'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT_TOKEN }}
          fetch-depth: 0         # 全履歴を取得して rebase が可能にする
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Cache deps
        uses: actions/cache@v4
        with:
          key: python-${{ hashFiles('requirements.txt') }}
          path: |
            ~/.cache/pip
            ~/.cache/torch/sentence_transformers
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # 追加: パッケージを editable でインストール
          pip install -e .
      - name: Scrape tech docs
        run: python scripts/scrape_docs.py --out tech.jsonl
      - name: Generate dialogs
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ST_CACHE: ${{ github.workspace }}/.cache/st
        PYTHONPATH: ${{ github.workspace }}
        run: |
          # 1) Q&A 生成 → dialogs.csv を runs/<exp_id>/ に保存
          python facade/collector.py --auto -n 50 \
          --q-provider openai --ai-provider openai \
          --quiet --summary \
          --output dialogs.csv
          # 2) 直近の runs ディレクトリを取得して変換
          run_dir=$(ls -td runs/* | head -n 1)
          python scripts/csv_to_jsonl.py "$run_dir/dialogs.csv" dialogs.jsonl
      - name: Auto tag
        run: |
          python scripts/classify_domain.py --inp tech.jsonl --out tech_tagged.jsonl --domain tech
          python scripts/classify_domain.py --inp dialogs.jsonl --out dialogs_tagged.jsonl --domain general
      - name: Merge dataset
        run: |
          python scripts/merge_to_dataset.py tech_tagged.jsonl dialogs_tagged.jsonl daily.jsonl
      - name: Upload current.csv as artefact
        uses: actions/upload-artifact@v4
        with:
          name: current-dataset-csv
          path: datasets/current.csv

      - name: Commit dataset
        id: commit
        run: |
          set -euo pipefail

          DATE=$(date +%Y%m%d)
          mkdir -p dataset
          cp daily.jsonl dataset/$DATE.jsonl

          git config --global user.name  "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          ############################  pull 最新 main ############################
          # まず fast‑forward で最速取得、競合したら rebase で解決
          git pull --ff-only  origin main || true
          git pull --rebase --autostash origin main || true

          ############################  変更が無ければスキップ  ####################
          git add dataset/$DATE.jsonl
          if git diff --cached --quiet; then
            echo "No dataset changes; skipping commit."
            echo "date=$DATE" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          git commit -m "Add dataset for $DATE"

          ###########################  push を 5 回リトライ  #######################
          set +e            # ← push 失敗を許容してループ
          for i in 1 2 3 4 5; do
            echo ">>> push attempt #$i ..."
            git push --force-with-lease origin HEAD:main
            if [ $? -eq 0 ]; then
              echo "Push succeeded."
              break
            fi
            echo "Push rejected – rebasing onto latest origin/main, retrying..."
            git pull --rebase --autostash origin main
            sleep 4
            if [ "$i" = 5 ]; then
              echo "Push failed after 5 attempts, aborting." >&2
              set -e
              exit 1
            fi
          done
          set -e            # 安全のため再有効化

          echo "date=$DATE" >> "$GITHUB_OUTPUT"

      # pull が競合等で失敗すると上記 set -e によりジョブは fail します
      # その場合は手動で main を更新してから再実行してください
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: dataset_today
          path: dataset/${{ steps.commit.outputs.date }}.jsonl
          retention-days: 30

  #----------------------------------------------
  # 追加：再計算 Job  (build が終わってから走る)
  #----------------------------------------------
  recalc:
    needs: build                     # ← artefact を受け取るため依存させる
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: ${{ github.workspace }}
      ST_CACHE:   ${{ github.workspace }}/.cache/st
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install deps
        run: |
          pip install -r requirements.txt
          pip install -e .

      - name: Download dataset artefact
        uses: actions/download-artifact@v4
        with:
          name: current-dataset-csv     # ← build Job で付けた名前
          path: datasets                # datasets/current.csv が展開される

      - name: Recalculate PoR/ΔE v4
        run: |
          python scripts/recalc_scores_v4.py \
            --infile  datasets/current.csv \
            --outfile datasets/current_recalc.parquet

      - name: Upload recalculated dataset
        uses: actions/upload-artifact@v4
        with:
          name: recalculated-dataset
          path: datasets/current_recalc.parquet
