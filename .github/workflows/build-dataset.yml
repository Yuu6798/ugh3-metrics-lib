name: Build Dataset

on:
  workflow_dispatch:
    inputs:
      turns:
        type: number
        default: 30
  schedule:
    - cron: '0 3 * * *'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT_TOKEN }}
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Cache deps
        uses: actions/cache@v4
        with:
          key: python-${{ hashFiles('requirements.txt') }}
          path: |
            ~/.cache/pip
            ~/.cache/torch/sentence_transformers
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # 追加: パッケージを editable でインストール
          pip install -e .
      - name: Scrape tech docs
        run: python scripts/scrape_docs.py --out tech.jsonl
      - name: Generate dialogs
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ST_CACHE: ${{ github.workspace }}/.cache/st
        PYTHONPATH: ${{ github.workspace }}
        run: |
          # 1) Q&A 生成 → dialogs.csv を runs/<exp_id>/ に保存
          python facade/collector.py --auto -n 50 \
          --q-provider openai --ai-provider openai \
          --quiet --summary \
          --output dialogs.csv
          # 2) 直近の runs ディレクトリを取得して変換
          run_dir=$(ls -td runs/* | head -n 1)
          python scripts/csv_to_jsonl.py "$run_dir/dialogs.csv" dialogs.jsonl
      - name: Auto tag
        run: |
          python scripts/classify_domain.py --inp tech.jsonl --out tech_tagged.jsonl --domain tech
          python scripts/classify_domain.py --inp dialogs.jsonl --out dialogs_tagged.jsonl --domain general
      - name: Merge dataset
        run: |
          python scripts/merge_to_dataset.py tech_tagged.jsonl dialogs_tagged.jsonl daily.jsonl
      - name: Upload current.csv as artefact
        uses: actions/upload-artifact@v4
        with:
          name: current-dataset-csv
          path: datasets/current.csv

      - name: Commit dataset      #  ← 既存のコミットステップは下にずらす
        id: commit
        run: |
          DATE=$(date +%Y%m%d)
          mkdir -p dataset
          cp daily.jsonl dataset/$DATE.jsonl
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add dataset/$DATE.jsonl
          git commit -m "Add dataset for $DATE" || echo "No changes"
          git push
          echo "date=$DATE" >> "$GITHUB_OUTPUT"
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: dataset_today
          path: dataset/${{ steps.commit.outputs.date }}.jsonl
          retention-days: 30
